{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traing Detectron Model on Custom Medical Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "from generate_dataset import my_dataset_function\n",
    "\n",
    "\n",
    "# Aggiungi il percorso della cartella detectron2\n",
    "sys.path.append(os.path.abspath(\"/detectron2_repo\"))\n",
    "\n",
    "from detectron2_repo.detectron2.engine import DefaultTrainer, DefaultPredictor\n",
    "from detectron2_repo.detectron2.config import get_cfg\n",
    "from detectron2_repo.detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "\n",
    "script_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Registrazione del dataset in formato COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "namespace(name='brain_mri_train', thing_classes=['brain'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DatasetCatalog.register(\"brain_mri_train\", lambda: my_dataset_function())\n",
    "DatasetCatalog.register(\"brain_mri_val\", lambda: my_dataset_function())\n",
    "\n",
    "# Imposta le classi (se non l'hai gi√† fatto)\n",
    "MetadataCatalog.get(\"brain_mri_train\").set(thing_classes=[\"background\", \"edema\", \"non-enhancing tumor\", \"enhancing tumour\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Configurazione del modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.DATASETS.TRAIN = (\"brain_mri_train\",)\n",
    "cfg.DATASETS.TEST = (\"brain_mri_val\",)\n",
    "cfg.MODEL.WEIGHTS = \"detectron2://ImageNetPretrained/MSRA/R-50.pkl\"  # Modello pre-addestrato\n",
    "cfg.DATALOADER.NUM_WORKERS = 0\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2 #immagini per batch\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 80 # Numero di ROI per immagine\n",
    "cfg.SOLVER.BASE_LR = 0.00025 #learning rate\n",
    "cfg.SOLVER.MAX_ITER = 500  # iterazioni massime\n",
    "cfg.SOLVER.WARMUP_ITERS = 50  # aumenta gradualmente il LR nelle prime x iterazioni fino a valore\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 4  # Cambia in base al numero delle classi\n",
    "cfg.MODEL.DEVICE = \"cpu\"  # Imposta l'uso della CPU\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.3 #Soglia di confidenza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Addestramento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/12 21:32:46 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 6 images left.\n",
      "\u001b[32m[12/12 21:32:46 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|   brain    | 11           |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[12/12 21:32:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(800,), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[12/12 21:32:46 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[12/12 21:32:46 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[12/12 21:32:46 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/12 21:32:46 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
      "\u001b[32m[12/12 21:32:46 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=2\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/12 21:32:46 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n",
      "\u001b[32m[12/12 21:32:46 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/MSRA/R-50.pkl ...\n",
      "\u001b[32m[12/12 21:32:46 d2.checkpoint.c2_model_loading]: \u001b[0mRenaming Caffe2 weights ......\n",
      "\u001b[32m[12/12 21:32:46 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with submodule model - Total num: 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}\u001b[0m\n",
      "\u001b[34mproposal_generator.rpn_head.conv.{bias, weight}\u001b[0m\n",
      "\u001b[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mfc1000.{bias, weight}\u001b[0m\n",
      "  \u001b[35mstem.conv1.bias\u001b[0m\n",
      "/Users/gianmariadifronzo/anaconda3/lib/python3.11/site-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3596.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/12 21:36:33 d2.utils.events]: \u001b[0m eta: 1:30:23  iter: 19  total_loss: 1.942  loss_cls: 0.5938  loss_box_reg: 0.4447  loss_rpn_cls: 0.6894  loss_rpn_loc: 0.2263    time: 11.3297  last_time: 11.2664  data_time: 0.0210  last_data_time: 0.0202   lr: 9.5155e-05  \n",
      "\u001b[32m[12/12 21:40:20 d2.utils.events]: \u001b[0m eta: 1:28:10  iter: 39  total_loss: 1.724  loss_cls: 0.3399  loss_box_reg: 0.5787  loss_rpn_cls: 0.6473  loss_rpn_loc: 0.1448    time: 11.3234  last_time: 11.7918  data_time: 0.0237  last_data_time: 0.0200   lr: 0.00019505  \n",
      "\u001b[32m[12/12 21:44:16 d2.utils.events]: \u001b[0m eta: 1:25:35  iter: 59  total_loss: 1.745  loss_cls: 0.2685  loss_box_reg: 0.792  loss_rpn_cls: 0.5811  loss_rpn_loc: 0.1022    time: 11.4998  last_time: 11.6430  data_time: 0.0195  last_data_time: 0.0182   lr: 0.00025  \n",
      "\u001b[32m[12/12 21:48:17 d2.utils.events]: \u001b[0m eta: 1:22:46  iter: 79  total_loss: 1.395  loss_cls: 0.2218  loss_box_reg: 0.588  loss_rpn_cls: 0.4946  loss_rpn_loc: 0.09124    time: 11.6391  last_time: 12.7471  data_time: 0.0214  last_data_time: 0.0279   lr: 0.00025  \n",
      "\u001b[32m[12/12 21:52:19 d2.utils.events]: \u001b[0m eta: 1:19:13  iter: 99  total_loss: 1.482  loss_cls: 0.1874  loss_box_reg: 0.7374  loss_rpn_cls: 0.4214  loss_rpn_loc: 0.1175    time: 11.7283  last_time: 12.3102  data_time: 0.0204  last_data_time: 0.0126   lr: 0.00025  \n",
      "\u001b[32m[12/12 21:56:21 d2.utils.events]: \u001b[0m eta: 1:15:26  iter: 119  total_loss: 1.354  loss_cls: 0.1478  loss_box_reg: 0.7118  loss_rpn_cls: 0.3785  loss_rpn_loc: 0.08213    time: 11.7967  last_time: 12.3475  data_time: 0.0210  last_data_time: 0.0229   lr: 0.00025  \n",
      "\u001b[32m[12/12 22:00:21 d2.utils.events]: \u001b[0m eta: 1:11:33  iter: 139  total_loss: 1.294  loss_cls: 0.1465  loss_box_reg: 0.7511  loss_rpn_cls: 0.3017  loss_rpn_loc: 0.0515    time: 11.8204  last_time: 12.9002  data_time: 0.0204  last_data_time: 0.0216   lr: 0.00025  \n",
      "\u001b[32m[12/12 22:04:34 d2.utils.events]: \u001b[0m eta: 1:07:42  iter: 159  total_loss: 1.265  loss_cls: 0.1236  loss_box_reg: 0.7304  loss_rpn_cls: 0.2754  loss_rpn_loc: 0.07697    time: 11.9304  last_time: 13.1452  data_time: 0.0210  last_data_time: 0.0117   lr: 0.00025  \n",
      "\u001b[32m[12/12 22:08:42 d2.utils.events]: \u001b[0m eta: 1:04:03  iter: 179  total_loss: 1.234  loss_cls: 0.1202  loss_box_reg: 0.7033  loss_rpn_cls: 0.2412  loss_rpn_loc: 0.04463    time: 11.9740  last_time: 12.5854  data_time: 0.0246  last_data_time: 0.0112   lr: 0.00025  \n",
      "\u001b[32m[12/12 22:12:52 d2.utils.events]: \u001b[0m eta: 1:00:20  iter: 199  total_loss: 1.087  loss_cls: 0.1021  loss_box_reg: 0.6577  loss_rpn_cls: 0.2381  loss_rpn_loc: 0.06535    time: 12.0265  last_time: 12.6062  data_time: 0.0219  last_data_time: 0.0287   lr: 0.00025  \n",
      "\u001b[32m[12/12 22:16:52 d2.utils.events]: \u001b[0m eta: 0:56:18  iter: 219  total_loss: 1.048  loss_cls: 0.1067  loss_box_reg: 0.6259  loss_rpn_cls: 0.2345  loss_rpn_loc: 0.06879    time: 12.0254  last_time: 11.7290  data_time: 0.0214  last_data_time: 0.0087   lr: 0.00025  \n",
      "\u001b[32m[12/12 22:20:58 d2.utils.events]: \u001b[0m eta: 0:52:33  iter: 239  total_loss: 1.012  loss_cls: 0.08803  loss_box_reg: 0.6052  loss_rpn_cls: 0.2139  loss_rpn_loc: 0.07844    time: 12.0467  last_time: 12.5179  data_time: 0.0249  last_data_time: 0.0442   lr: 0.00025  \n",
      "\u001b[32m[12/12 22:25:15 d2.utils.events]: \u001b[0m eta: 0:48:53  iter: 259  total_loss: 0.9969  loss_cls: 0.09212  loss_box_reg: 0.6099  loss_rpn_cls: 0.2113  loss_rpn_loc: 0.05976    time: 12.1083  last_time: 13.2399  data_time: 0.0222  last_data_time: 0.0276   lr: 0.00025  \n",
      "\u001b[32m[12/12 22:29:23 d2.utils.events]: \u001b[0m eta: 0:44:56  iter: 279  total_loss: 0.9014  loss_cls: 0.08072  loss_box_reg: 0.5495  loss_rpn_cls: 0.1974  loss_rpn_loc: 0.1088    time: 12.1308  last_time: 12.7972  data_time: 0.0215  last_data_time: 0.0203   lr: 0.00025  \n",
      "\u001b[32m[12/12 22:33:36 d2.utils.events]: \u001b[0m eta: 0:41:01  iter: 299  total_loss: 1.002  loss_cls: 0.1108  loss_box_reg: 0.6106  loss_rpn_cls: 0.1984  loss_rpn_loc: 0.08053    time: 12.1637  last_time: 10.8963  data_time: 0.0226  last_data_time: 0.0094   lr: 0.00025  \n",
      "\u001b[32m[12/12 22:37:46 d2.utils.events]: \u001b[0m eta: 0:37:00  iter: 319  total_loss: 0.9681  loss_cls: 0.09755  loss_box_reg: 0.5386  loss_rpn_cls: 0.1821  loss_rpn_loc: 0.06976    time: 12.1859  last_time: 11.9966  data_time: 0.0231  last_data_time: 0.0263   lr: 0.00025  \n",
      "\u001b[32m[12/12 22:41:58 d2.utils.events]: \u001b[0m eta: 0:32:56  iter: 339  total_loss: 0.9608  loss_cls: 0.08363  loss_box_reg: 0.5777  loss_rpn_cls: 0.1719  loss_rpn_loc: 0.0632    time: 12.2102  last_time: 12.3955  data_time: 0.0259  last_data_time: 0.0219   lr: 0.00025  \n",
      "\u001b[32m[12/12 22:46:09 d2.utils.events]: \u001b[0m eta: 0:28:52  iter: 359  total_loss: 0.8461  loss_cls: 0.07557  loss_box_reg: 0.4906  loss_rpn_cls: 0.1849  loss_rpn_loc: 0.06331    time: 12.2287  last_time: 13.2767  data_time: 0.0210  last_data_time: 0.0196   lr: 0.00025  \n",
      "\u001b[32m[12/12 22:50:22 d2.utils.events]: \u001b[0m eta: 0:24:48  iter: 379  total_loss: 0.8755  loss_cls: 0.06907  loss_box_reg: 0.5283  loss_rpn_cls: 0.1699  loss_rpn_loc: 0.06043    time: 12.2515  last_time: 12.0777  data_time: 0.0231  last_data_time: 0.0198   lr: 0.00025  \n",
      "\u001b[32m[12/12 22:54:37 d2.utils.events]: \u001b[0m eta: 0:20:41  iter: 399  total_loss: 0.8909  loss_cls: 0.07856  loss_box_reg: 0.5834  loss_rpn_cls: 0.1727  loss_rpn_loc: 0.08587    time: 12.2756  last_time: 12.9005  data_time: 0.0238  last_data_time: 0.0293   lr: 0.00025  \n",
      "\u001b[32m[12/12 22:58:48 d2.utils.events]: \u001b[0m eta: 0:16:34  iter: 419  total_loss: 0.7738  loss_cls: 0.07273  loss_box_reg: 0.47  loss_rpn_cls: 0.1568  loss_rpn_loc: 0.03098    time: 12.2903  last_time: 12.0144  data_time: 0.0216  last_data_time: 0.0198   lr: 0.00025  \n",
      "\u001b[32m[12/12 23:02:59 d2.utils.events]: \u001b[0m eta: 0:12:26  iter: 439  total_loss: 0.7489  loss_cls: 0.0665  loss_box_reg: 0.4727  loss_rpn_cls: 0.152  loss_rpn_loc: 0.03631    time: 12.3006  last_time: 12.8573  data_time: 0.0208  last_data_time: 0.0184   lr: 0.00025  \n",
      "\u001b[32m[12/12 23:07:02 d2.utils.events]: \u001b[0m eta: 0:08:18  iter: 459  total_loss: 0.7922  loss_cls: 0.05978  loss_box_reg: 0.4608  loss_rpn_cls: 0.1577  loss_rpn_loc: 0.09752    time: 12.2948  last_time: 11.9206  data_time: 0.0208  last_data_time: 0.0210   lr: 0.00025  \n",
      "\u001b[32m[12/12 23:11:02 d2.utils.events]: \u001b[0m eta: 0:04:08  iter: 479  total_loss: 0.7701  loss_cls: 0.0539  loss_box_reg: 0.468  loss_rpn_cls: 0.1417  loss_rpn_loc: 0.08009    time: 12.2833  last_time: 10.4006  data_time: 0.0189  last_data_time: 0.0093   lr: 0.00025  \n",
      "\u001b[32m[12/12 23:15:09 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 499  total_loss: 0.7452  loss_cls: 0.06238  loss_box_reg: 0.4473  loss_rpn_cls: 0.1408  loss_rpn_loc: 0.07497    time: 12.2851  last_time: 12.9638  data_time: 0.0204  last_data_time: 0.0283   lr: 0.00025  \n",
      "\u001b[32m[12/12 23:15:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/12 23:15:11 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[12/12 23:15:11 d2.data.common]: \u001b[0mSerializing 6 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/12 23:15:11 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n"
     ]
    }
   ],
   "source": [
    "# Verifica se il modello addestrato esiste gi√†\n",
    "model_path = os.path.join(script_dir, \"output\", \"model_final.pth\")\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    print(\"Modello gi√† addestrato trovato, caricando il modello...\")\n",
    "    cfg.MODEL.WEIGHTS = model_path\n",
    "    # Carica il modello addestrato\n",
    "    predictor = DefaultPredictor(cfg)\n",
    "else:\n",
    "    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "    trainer = DefaultTrainer(cfg)\n",
    "    trainer.resume_or_load(resume=False)\n",
    "    trainer.train()\n",
    "\n",
    "    # Imposta il modello addestrato\n",
    "    cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # Salva il modello addestrato\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.Inferenza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/12 23:15:11 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from ./output/model_final.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gianmariadifronzo/anaconda3/lib/python3.11/site-packages/fvcore/common/checkpoint.py:252: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=torch.device(\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instances': Instances(num_instances=0, image_height=1534, image_width=1433, fields=[pred_boxes: Boxes(tensor([], size=(0, 4))), scores: tensor([]), pred_classes: tensor([], dtype=torch.int64)])}\n"
     ]
    }
   ],
   "source": [
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # Modello addestrato\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # Soglia per l'inferenza\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "# Carica un'immagine MRI per l'inferenza\n",
    "image_path = os.path.join(script_dir, \"test\", \"test3.jpg\")\n",
    "image = cv2.imread(image_path)\n",
    "outputs = predictor(image)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.Test sull'immagine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizza i risultati con bordi rossi per le istanze rilevate\n",
    "v = Visualizer(image[:,:,::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "v = v.draw_instance_predictions(outputs['instances'].to('cpu'))\n",
    "img = v.get_image()[:, :, ::-1]\n",
    "cv2.imwrite('output.jpg', img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
